{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic test for Nvidia DALI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "import torch.optim as optim\n",
    "from IPython.core.debugger import set_trace\n",
    "import pandas as pd\n",
    "import lmdb\n",
    "import pickle\n",
    "import h5py\n",
    "from random import shuffle\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10-batches-py  medium_imgs  small_hdf5  small_lmdb\r\n",
      "medium_hdf5\t     medium_lmdb  small_imgs\r\n"
     ]
    }
   ],
   "source": [
    "!ls {path_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastNet(nn.Module):\n",
    "    # Just do a single convolution followed by a linear layer\n",
    "    # Made to be simple to emphasize affect of image loading\n",
    "    # and augmentation\n",
    "    def __init__(self, num_cl):\n",
    "        super(FastNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 64, 3, stride=2)\n",
    "        self.fc = nn.Linear(64, num_cl)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image folder no augmentation pipeline\n",
    "class ImageNaPipeline(Pipeline):\n",
    "    def __init__(self, path_imgs, num_batch, num_threads, device_id):\n",
    "        super(ImageNaPipeline, self).__init__(num_batch, num_threads, device_id)\n",
    "        # Use FileReader to read images and get labels from class folder  \n",
    "        self.input = ops.FileReader(file_root=path_imgs, \n",
    "                                    random_shuffle=True)\n",
    "        \n",
    "        # Attempt to decode on gpu\n",
    "        self.decode = ops.ImageDecoder(device='mixed', \n",
    "                                       output_type=types.RGB)\n",
    "        \n",
    "        # This has the important action of transposing channel from last to 2nd dimension\n",
    "        # Note that normalization is done WRT raw uint8 values (so they are [0, 255])\n",
    "        self.cmnp = ops.CropMirrorNormalize(device='gpu',\n",
    "                                            output_dtype=types.FLOAT,\n",
    "                                            output_layout=types.NCHW,\n",
    "                                            image_type=types.RGB,\n",
    "                                            mean=[0.5 * 255,0.5 * 255,0.5 * 255],\n",
    "                                            std= [0.5 * 255,0.5 * 255,0.5 * 255])\n",
    "\n",
    "    def define_graph(self):\n",
    "        imgs, labels = self.input() # Automagically gets labels from class folder\n",
    "        imgs = self.decode(imgs)    # Images are decoded on gpu (if jpg)\n",
    "        imgs = self.cmnp(imgs)      # This also converts from NHWC -> NCHW\n",
    "        return (imgs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image folder with augmentation pipeline\n",
    "class ImageAugPipeline(Pipeline):\n",
    "    def __init__(self, path_imgs, num_batch, num_threads, device_id):\n",
    "        super(ImageAugPipeline, self).__init__(num_batch, num_threads, device_id)\n",
    "        # Use FileReader to read images and get labels from class folder  \n",
    "        self.input = ops.FileReader(file_root=path_imgs, \n",
    "                                    random_shuffle=True)\n",
    "        \n",
    "        # Attempt to decode on gpu\n",
    "        self.decode = ops.ImageDecoder(device='mixed', \n",
    "                                       output_type=types.RGB)\n",
    "        \n",
    "        \n",
    "        # Random rotation\n",
    "        self.rng = ops.Uniform(range=(-30.0, 30.0))\n",
    "        self.rotate = ops.Rotate(device='gpu',\n",
    "                                 fill_value=0.0,\n",
    "                                 keep_size=True)\n",
    "        \n",
    "        # This has the important action of transposing channel from last to 2nd dimension\n",
    "        # Note that normalization is done WRT raw uint8 values (so they are [0, 255])\n",
    "        self.cmnp = ops.CropMirrorNormalize(device='gpu',\n",
    "                                            output_dtype=types.FLOAT,\n",
    "                                            output_layout=types.NCHW,\n",
    "                                            image_type=types.RGB,\n",
    "                                            mean=[0.5 * 255,0.5 * 255,0.5 * 255],\n",
    "                                            std= [0.5 * 255,0.5 * 255,0.5 * 255])\n",
    "\n",
    "    def define_graph(self):\n",
    "        imgs, labels = self.input()          # Automagically gets labels from class folder\n",
    "        imgs = self.decode(imgs)             # Images are decoded on gpu (if jpg)\n",
    "        imgs = self.rotate(imgs, \n",
    "                           angle=self.rng()) # Rotation on gpu\n",
    "        imgs = self.cmnp(imgs)               # This also converts from NHWC -> NCHW\n",
    "        return (imgs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExternalInputIterator(object):\n",
    "    def __init__(self, path_root, num_batch, subsamples=None):\n",
    "        self.path_root = path_root\n",
    "        self.num_batch = num_batch\n",
    "        self.subsamples = subsamples\n",
    "        self.samples = self._get_samples()\n",
    "        \n",
    "    def _get_samples(self):\n",
    "        samples = [(p, int(p.parent.stem)) for p in self.path_root.glob('*/*')]\n",
    "        \n",
    "        if self.subsamples is not None:\n",
    "            samples = [samples[i] for i in np.random.choice(len(samples), self.subsamples, replace=False)]\n",
    "            \n",
    "        return samples\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.idx = 0\n",
    "        shuffle(self.samples)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.idx >= len(self.samples):\n",
    "            raise StopIteration\n",
    "        \n",
    "        batch = []\n",
    "        labels = []\n",
    "        for _ in range(self.num_batch):\n",
    "            file_img, label = self.samples[self.idx]\n",
    "            with open(file_img, 'rb') as f:\n",
    "                batch.append(np.frombuffer(f.read(), dtype=np.uint8))\n",
    "            labels.append(np.array([label], dtype=np.uint8))\n",
    "            self.idx = (self.idx + 1)%len(self.samples)\n",
    "        return (batch, labels)\n",
    "    \n",
    "    next = __next__\n",
    "    \n",
    "    \n",
    "class ExternalSourcePipeline(Pipeline):\n",
    "    def __init__(self, external_data, num_batch, num_threads, device_id):\n",
    "        super(ExternalSourcePipeline, self).__init__(num_batch,\n",
    "                                                     num_threads,\n",
    "                                                     device_id,\n",
    "                                                     seed=12)\n",
    "        self.external_data = external_data\n",
    "        self.es_img = ops.ExternalSource()\n",
    "        self.es_label = ops.ExternalSource()\n",
    "        \n",
    "        self.decode = ops.ImageDecoder(device='mixed',\n",
    "                                       output_type=types.RGB)\n",
    "        \n",
    "        # This has the important action of transposing channel from last to 2nd dimension\n",
    "        # Note that normalization is done WRT raw uint8 values (so they are [0, 255])\n",
    "        self.cmnp = ops.CropMirrorNormalize(device='gpu',\n",
    "                                            output_dtype=types.FLOAT,\n",
    "                                            output_layout=types.NCHW,\n",
    "                                            image_type=types.RGB,\n",
    "                                            mean=[0.5 * 255,0.5 * 255,0.5 * 255],\n",
    "                                            std= [0.5 * 255,0.5 * 255,0.5 * 255])\n",
    "        \n",
    "        # Initialize iterator\n",
    "        self.iterator = iter(self.external_data)\n",
    "        \n",
    "    def define_graph(self):\n",
    "        self.imgs = self.es_img()\n",
    "        self.labels = self.es_label()\n",
    "        imgs = self.decode(self.imgs)\n",
    "        imgs = self.cmnp(imgs)\n",
    "        return (imgs, self.labels)\n",
    "\n",
    "    def iter_setup(self):        \n",
    "        try:\n",
    "            (imgs, labels) = self.iterator.next()\n",
    "            self.feed_input(self.imgs, imgs)\n",
    "            self.feed_input(self.labels, labels)\n",
    "        except StopIteration:\n",
    "            self.iterator = iter(self.external_data)\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(di, model, loss, opt, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(di):\n",
    "            X = data[0][\"data\"]\n",
    "            y = data[0][\"label\"].squeeze().cuda().long()\n",
    "                        \n",
    "            opt.zero_grad()    # Zero gradients\n",
    "            y_hat = model(X)   # Forward pass\n",
    "            l = loss(y_hat, y) # Loss\n",
    "            l.backward()       # Compute gradients\n",
    "            opt.step()         # Step\n",
    "            \n",
    "        # print statistics\n",
    "        print(f'Epoch: {epoch}; Loss: {l.item()}')\n",
    "        \n",
    "        # Reset iterator\n",
    "        di.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_imgs=path_data/'small_imgs'/'png'\n",
    "num_batch=256\n",
    "num_threads=12\n",
    "device_id=0 \n",
    "num_samples=40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Loss: 2.325206756591797\n",
      "CPU times: user 2.95 s, sys: 859 ms, total: 3.81 s\n",
      "Wall time: 765 ms\n"
     ]
    }
   ],
   "source": [
    "pipe = ImageNaPipeline(path_imgs=path_imgs,\n",
    "                       num_batch=num_batch,\n",
    "                       num_threads=num_threads,\n",
    "                       device_id=device_id)\n",
    "\n",
    "pipe.build()\n",
    "di = DALIGenericIterator(pipe, ['data', 'label'], num_samples)\n",
    "\n",
    "model = FastNet(10).cuda()\n",
    "opt = optim.SGD(model.parameters(), lr=0.001)\n",
    "%time train(di, model, loss, opt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very fast; add dali-style augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Loss: 2.3065807819366455\n",
      "CPU times: user 2.74 s, sys: 761 ms, total: 3.5 s\n",
      "Wall time: 691 ms\n"
     ]
    }
   ],
   "source": [
    "pipe = ImageAugPipeline(path_imgs=path_imgs,\n",
    "                        num_batch=num_batch,\n",
    "                        num_threads=num_threads,\n",
    "                        device_id=device_id)\n",
    "\n",
    "pipe.build()\n",
    "di = DALIGenericIterator(pipe, ['data', 'label'], num_samples)\n",
    "\n",
    "model = FastNet(10).cuda()\n",
    "opt = optim.SGD(model.parameters(), lr=0.001)\n",
    "%time train(di, model, loss, opt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try external source pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Loss: 2.279061794281006\n",
      "CPU times: user 2.73 s, sys: 630 ms, total: 3.36 s\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "pipe = ExternalSourcePipeline(external_data=ExternalInputIterator(path_imgs, num_batch, num_samples),\n",
    "                              num_batch=num_batch, \n",
    "                              num_threads=num_threads, \n",
    "                              device_id=device_id)\n",
    "\n",
    "pipe.build()\n",
    "di = DALIGenericIterator(pipe, \n",
    "                         ['data', 'label'], \n",
    "                         num_samples,\n",
    "                         fill_last_batch=False,\n",
    "                         last_batch_padded=True)\n",
    "\n",
    "model = FastNet(10).cuda()\n",
    "opt = optim.SGD(model.parameters(), lr=0.001)\n",
    "%time train(di, model, loss, opt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_imgs=path_data/'medium_imgs'/'png'\n",
    "num_batch=64\n",
    "num_threads=12\n",
    "device_id=0 \n",
    "num_samples=4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Loss: 2.311649799346924\n",
      "CPU times: user 4.17 s, sys: 305 ms, total: 4.48 s\n",
      "Wall time: 895 ms\n"
     ]
    }
   ],
   "source": [
    "pipe = ImageNaPipeline(path_imgs=path_imgs,\n",
    "                       num_batch=num_batch,\n",
    "                       num_threads=num_threads,\n",
    "                       device_id=device_id)\n",
    "\n",
    "pipe.build()\n",
    "di = DALIGenericIterator(pipe, ['data', 'label'], num_samples)\n",
    "\n",
    "model = FastNet(10).cuda()\n",
    "opt = optim.SGD(model.parameters(), lr=0.001)\n",
    "%time train(di, model, loss, opt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incredibly fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Loss: 2.3008930683135986\n",
      "CPU times: user 4.13 s, sys: 296 ms, total: 4.43 s\n",
      "Wall time: 861 ms\n"
     ]
    }
   ],
   "source": [
    "pipe = ImageAugPipeline(path_imgs=path_imgs,\n",
    "                        num_batch=num_batch,\n",
    "                        num_threads=num_threads,\n",
    "                        device_id=device_id)\n",
    "\n",
    "pipe.build()\n",
    "di = DALIGenericIterator(pipe, ['data', 'label'], num_samples)\n",
    "\n",
    "model = FastNet(10).cuda()\n",
    "opt = optim.SGD(model.parameters(), lr=0.001)\n",
    "%time train(di, model, loss, opt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Loss: 2.2975008487701416\n",
      "CPU times: user 6.86 s, sys: 861 ms, total: 7.72 s\n",
      "Wall time: 2.68 s\n"
     ]
    }
   ],
   "source": [
    "pipe = ExternalSourcePipeline(external_data=ExternalInputIterator(path_imgs, num_batch, num_samples),\n",
    "                              num_batch=num_batch, \n",
    "                              num_threads=num_threads, \n",
    "                              device_id=device_id)\n",
    "\n",
    "pipe.build()\n",
    "di = DALIGenericIterator(pipe, ['data', 'label'], num_samples)\n",
    "\n",
    "model = FastNet(10).cuda()\n",
    "opt = optim.SGD(model.parameters(), lr=0.001)\n",
    "%time train(di, model, loss, opt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
